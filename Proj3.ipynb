{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project 3: NLP an Neural Networks #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Mckayla Ashley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "\n",
    "Precept_word2vec_nn.ipynb\n",
    "\n",
    "Word2Vec:\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "https://rare-technologies.com/word2vec-tutorial/#app\n",
    "\n",
    "LDA:\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "\n",
    "NN:\n",
    "https://keras.io/guides/training_with_built_in_methods/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLP and Word2Vec \n",
    "### a. Please describe what is meant by a \"vector embedding\" of words in Word2Vec\n",
    "A vector embedding of words in Word2Vec means words are represented numerically as vectors in n-dimensional space, where n is the chosen embedding size of the vector. A higher dimension can tell us more about the words and complex relationships, whereas a lower dimension is more compact. \n",
    "\n",
    "Perceptrons, used for making binary decisions, take in numerical inputs, multiplies them by corresponding weights, adds them up, and returns a prediction of either 1 or 0. Then, it adjusts the weights based on whether the prediction was correct or not. Word2Vec often uses multiple perceptrons stacked together, a neural network, to predict words and learn word relationships. Word2Vec turns words into vectors by looking at how words often show up in sentences, and quantifying their similarities through vector representation. The \"nearby,\" or most similar vectors, are computed using cosine similarity-- where vectors that share the smallest angle are most similar.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Please use the pre-trained gensim 'glove-wiki-gigaword-50’ Word2Vec model to determine reasonable synonyms for the following words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the \"glove-wiki-gigaword-50\" embeddings\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Tiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tigers', 0.723923921585083),\n",
       " ('woods', 0.6852725148200989),\n",
       " ('warrior', 0.6822083592414856),\n",
       " ('ltte', 0.6664599776268005),\n",
       " ('wild', 0.6495701670646667)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('tiger', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 most similar words to \"Tiger\" are \"tigers\", \"woods\", \"warrior\", \"ltte\", and \"wild\". It is reasonable to consider \"tigers\" and \"woods\" as synonyms based on the model. However, the term \"woods\" being the second-most similar is likely due to the professional golfer Tiger Woods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Awesome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unbelievable', 0.8638607859611511),\n",
       " ('amazing', 0.8620665669441223),\n",
       " ('incredible', 0.8470884561538696),\n",
       " ('fantastic', 0.8059698343276978),\n",
       " ('marvelous', 0.7899898886680603)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('awesome', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five words most similar to \"awesome\" are \"unbelievable\", \"amazing\", \"incredible\", \"fantastic\", and \"marvelous\". These are reasonable synonyms as they have the highest cosine similarity and they are all adjectives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### iv. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('information', 0.8329989314079285),\n",
       " ('tracking', 0.81246018409729),\n",
       " ('database', 0.8122304677963257),\n",
       " ('analysis', 0.7966611981391907),\n",
       " ('applications', 0.7923666834831238)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('data', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three words most similar to \"data\" are \"information\", \"tracking\", and \"database\". \"Information\" is the most reasonable synoynm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('album', 0.9297007918357849),\n",
       " ('songs', 0.9009864330291748),\n",
       " ('soundtrack', 0.8414769172668457),\n",
       " ('albums', 0.8228148221969604),\n",
       " ('pop', 0.8219154477119446)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('song', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three most similar words to \"song\" are \"album\", \"songs\", and \"soundtrack\". These are reasonable synonyms and all make sense together, as multiple songs make up an album, songs is the plural form, and soundtrack is an album for a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Please use the pre-trained gensim ‘glove-wiki-gigawmodels to determine reasonable answers for the following analogies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. puppy : kitten :: dog : ?\n",
    "\n",
    "The top answer is \"cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analogy is puppy : kitten :: dog : cat\n"
     ]
    }
   ],
   "source": [
    "## Compute an analogy:   puppy : kitten :: dog : ?\n",
    "\n",
    "## \"(dog - puppy) + kitten\"\n",
    "\n",
    "result = glove_vectors.most_similar(negative=['puppy'], positive=['kitten', 'dog'], topn=1)\n",
    "\n",
    "print(f\"The analogy is puppy : kitten :: dog : {result[0][0]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. freshman: sophomore :: junior: ?\n",
    "The top answer is \"basketball\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analogy is freshman: sophomore :: junior: basketball\n"
     ]
    }
   ],
   "source": [
    "## Compute an analogy:   freshman: sophomore :: junior: ?\n",
    "\n",
    "## \"(junior - freshman) + sophomore\"\n",
    "\n",
    "result = glove_vectors.most_similar(negative=['freshman'], positive=['sophomore', 'junior'], topn=1)\n",
    "\n",
    "print(f\"The analogy is freshman: sophomore :: junior: {result[0][0]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. brother : sister :: grandson : ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top answer is \"granddaughter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analogy is brother : sister :: grandson : granddaughter\n"
     ]
    }
   ],
   "source": [
    "## Compute an analogy:   brother : sister :: grandson : ?\n",
    "\n",
    "## \"(grandson - brother) + sister\"\n",
    "\n",
    "result = glove_vectors.most_similar(negative=['brother'], positive=['sister', 'grandson'], topn=1)\n",
    "\n",
    "print(f\"The analogy is brother : sister :: grandson : {result[0][0]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLP and Topic Modelling\n",
    "### a. Please prepare the built-in “fake-news” corpus of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "corpus_data = api.load('fake-news')\n",
    "docs = [x[\"text\"] for x in corpus_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Please use Gensim to preprocess these documents by tokenizing and lemmatizing them and removing other small text/strings that you decide are not meaningful for NLP, as well as rare and scarce words.\n",
    "\n",
    "We remove rare and scarce words in Part C using the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 2] for doc in docs]\n",
    "\n",
    "# Remove stopwords\n",
    "docs = [[token for token in doc if token not in STOPWORDS] for doc in docs]\n",
    "\n",
    "# Lemmatize the documents\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Please use the Gensim Dictionary and dictionary.doc2bow to create a dictionary and a bag of words representation of your tokenized corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 60% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.6)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether we capture meaningful words\n",
    "# print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Please use the Gensim LDAModel to perform topic modelling of the corpus into 3 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "lda = models.LdaModel(\n",
    "    corpus = corpus,\n",
    "    id2word = dictionary,\n",
    "    num_topics = 3,\n",
    "    random_state = 10,\n",
    "    passes = 15,\n",
    "    alpha='auto'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. For each topic show the main words and use these to give a rough name to each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 1 is Presidential Election Campaigns, based on the words \"clinton\", \"trump\", \"hillary\", and \"election\".\n",
    "Topic 2 is U.S Government and Political Affairs, based on the words \"state\", \"war\", \"american\", and \"government\".\n",
    "Topic 3 is Society and Global Perspectives, based on the words \"people\", \"time\", \"year\", \"like\". and \"world\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.027*\"clinton\" + 0.018*\"trump\" + 0.016*\"hillary\" + 0.011*\"election\" + 0.010*\"email\"\n",
      "Topic 2: 0.008*\"state\" + 0.007*\"war\" + 0.006*\"american\" + 0.006*\"government\" + 0.006*\"trump\"\n",
      "Topic 3: 0.007*\"people\" + 0.006*\"time\" + 0.005*\"year\" + 0.005*\"like\" + 0.003*\"world\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda.print_topics(num_topics=3, num_words=5):\n",
    "    print(f\"Topic {idx + 1}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Classification\n",
    "### a. Please take the MNIST training dataset and split off the last 10,000 images as a validation data set. Then assign the other training images to a new training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorFlow version: 2.17.0\n",
      "keras version: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "## Import Keras and Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"tensorFlow version:\", tf.__version__)\n",
    "print(\"keras version:\", keras.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the builtin MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Please create a Neural Network with three dense hidden layers each having 32 nodes, and train it to classify the MNIST Data set over five epochs. For this please use your new training set and validation set respectively for model training and model performance reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defines the Neural Network model\n",
    "inputs = keras.Input(shape=(784,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "x_val = x_val.reshape(-1, 784).astype(\"float32\") / 255\n",
    "\n",
    "## Prepare the model with additional information about how to train it!  (i.e. \"compile\" it)\n",
    "model.compile(\n",
    "    optimizer='adam', #keras.optimizers.RMSprop(),  Optimizer Adam\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - loss: 0.7972 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9396\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.1689 - val_sparse_categorical_accuracy: 0.9514\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9554\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.1386 - val_sparse_categorical_accuracy: 0.9601\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "## Fit our model with the initial training data, and check it with the \"validation\" training data!\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5, # 5 epochs\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m25,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,688</span> (323.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,688\u001b[0m (323.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,562</span> (107.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,562\u001b[0m (107.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,126</span> (215.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m55,126\u001b[0m (215.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4425293505191803,\n",
       "  0.20567937195301056,\n",
       "  0.16604284942150116,\n",
       "  0.1427481770515442,\n",
       "  0.12371402233839035],\n",
       " 'sparse_categorical_accuracy': [0.8668000102043152,\n",
       "  0.9393799901008606,\n",
       "  0.9498199820518494,\n",
       "  0.9574800133705139,\n",
       "  0.9629600048065186],\n",
       " 'val_loss': [0.21168047189712524,\n",
       "  0.16890335083007812,\n",
       "  0.15615299344062805,\n",
       "  0.13860121369361877,\n",
       "  0.12821520864963531],\n",
       " 'val_sparse_categorical_accuracy': [0.9395999908447266,\n",
       "  0.9513999819755554,\n",
       "  0.9553999900817871,\n",
       "  0.960099995136261,\n",
       "  0.9624999761581421]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn about the model training history!\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. What is the performance of the model on the training and validation sets over the 5 epochs? Which of these do we expect is characteristic of model performance in new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on training data\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9694\n",
      "\n",
      "training loss: 0.1065206527709961, \n",
      "test acc: 0.9674199819564819\n",
      "\n",
      "Evaluate on validation data\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9610\n",
      "\n",
      "validation loss: 0.12821520864963531, \n",
      "validation acc: 0.9624999761581421\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training data using `evaluate`\n",
    "print(\"Evaluate on training data\")\n",
    "results = model.evaluate(x_train, y_train, batch_size=64)\n",
    "print(f\"\\ntraining loss: {results[0]}, \\ntest acc: {results[1]}\")\n",
    "\n",
    "# Evaluate the model on the validation data using `evaluate`\n",
    "print(\"\\nEvaluate on validation data\")\n",
    "results = model.evaluate(x_val, y_val, batch_size=64)\n",
    "print(f\"\\nvalidation loss: {results[0]}, \\nvalidation acc: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs with 0.1065 loss and 96.74% accuracy on training data. This is good loss, because 0 is the best possible (perfect prediction). The loss decreases over time. The model performs with 0.1282 loss and 96.25% for the validation data. This is slightly less accurate than the training data, to be expected, but still quite high. The validation accuracy is characteristic of new, unseen data, so it is a good indicator for how the model will perform on testing data. Since the training and validation accuracy are very similar, with loss decreasing and accuracy increasing over each epoch for both, we expect that the model is likely to perform well on new testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Check your model performance on the test set, and compare with your expectations in part c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9535\n",
      "\n",
      "test loss: 0.13321974873542786, \n",
      "test acc: 0.9580000042915344\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print(f\"\\ntest loss: {results[0]}, \\ntest acc: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs with 0.1332 loss and 95.80% accuracy for testing data. Compared to the validation data performance, the testing data has slightly higher loss and slightly lower accuracy, with a difference of +0.015 loss and -0.45% accuracy. This aligns with our expectation in part c because we expected the model to perform similarly to the validation data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
